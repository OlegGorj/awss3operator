#! validate-crd: deploy/chart/templates/0000_30_02-clusterserviceversion.crd.yaml
#! parse-kind: ClusterServiceVersion
apiVersion: operators.coreos.com/v1alpha1
kind: ClusterServiceVersion
metadata:
  name: awss3operator.1.0.1
  namespace: placeholder
  annotations:
    capabilities: Basic Install
    categories: Provisioning
    description: Manage the full lifecycle of installing, configuring and managing AWS S3 Provisioner.
    containerImage: quay.io/screeley44/aws-s3-provisioner:v1.0.0
    createdAt: 2019-05-02T16:12:00Z
    repository: https://github.com/yard-turkey/aws-s3-provisioner
    alm-examples: '[{"apiVersion":"apiextensions.k8s.io/v1beta1","kind":"CustomResourceDefinition","metadata":{"name":"objectbuckets.objectbucket.io"},"spec":{"group":"objectbucket.io","version":"v1alpha1","versions":[{"name": "v1alpha1","served":true,"storage":true}],"names":{"kind":"ObjectBucket","listKind":"ObjectBucketList","plural":"objectbuckets","singular":"objectbucket","shortNames":["ob","obs"]},"scope":"Cluster","subresources":{"status":{}}}},{"apiVersion":"apiextensions.k8s.io/v1beta1","kind":"CustomResourceDefinition","metadata":{"name":"objectbucketclaims.objectbucket.io"},"spec":{"version":"v1alpha1","versions":[{"name":"v1alpha1","served":true,"storage":true}],"group":"objectbucket.io","names":{"kind":"ObjectBucketClaim","listKind":"ObjectBucketClaimList","plural":"objectbucketclaims","singular":"objectbucketclaim","shortNames":["obc","obcs"]},"scope":"Namespaced","subresources":{"status":{}}}}]'
    certified: "false"
    support: OCTO
spec:
  replaces: awss3operator.1.0.0
  displayName: AWS S3 Operator
  description: |
    AWS S3 Operator will deploy the AWS S3 Provisioner which will dynamically or statically
    provision AWS S3 Bucket storage and access. The operator deploys the ObjectBucket (OB) and ObjectBucketClaim (OBC)
    CustomResourceDefinitions. The OB/OBC model follows the traditional Kubernetes PV/PVC pattern, when an OBC is detected
    the operator will act on the OBC to either provision a brand new S3 Bucket in AWS or gain access to an existing
    S3 Bucket in AWS. The operator produces an OB and ConfigMap and Secret which can then be consumed by application pods.
    
    **Important Note**: Currently, while in preview, this operator does not
    support automatic upgrades. You must remove the old version of the operator
    manually before installing a new version.

    ## Using AWS S3 Operator
    
    ### Administrator Creates Secret
    This secret will contain the elevated/admin privileges needed by the provisioner
    to properly access and create S3 Buckets and IAM users and policies. The AWS Access ID
    and AWS Secret Key will be needed for this.

    1. Create the Kubernetes Secret for the Provisioner's Owner Access.
    ```yaml
    apiVersion: v1
    kind: Secret
    metadata:
      name: s3-bucket-owner [1]
      namespace: s3-provisioner [2]
    type: Opaque
    data:
      AWS_ACCESS_KEY_ID: *base64 encoded value* [3]
      AWS_SECRET_ACCESS_KEY: *base64 encoded value* [4]

    ```
    1. Name of the secret, this will be referenced in StorageClass.
    1. Namespace where the Secret will exist.
    1. Your AWS_ACCESS_KEY_ID base64 encoded.
    1. Your AWS_SECRET_ACCESS_KEY base64 encoded.

    ```
     # kubectl create -f creds.yaml
    secret/s3-bucket-owner created
    ```

    ### Administrator Creates StorageClass
    The StorageClass defines the name of the provisioner and holds other properties that are needed to provision a new bucket, including
    the Owner Secret and Namespace, and the AWS Region.

    #### Greenfield Example:
    For Greenfield, a new, dynamic bucket will be generated.

    1. Create the Kubernetes StorageClass for the Provisioner.
    ```yaml
    kind: StorageClass
    apiVersion: storage.k8s.io/v1
    metadata:
      name: s3-buckets [1]
    provisioner: aws-s3.io/bucket [2]
    parameters:
      region: us-west-1 [3]
      secretName: s3-bucket-owner [4]
      secretNamespace: s3-provisioner [5]
    reclaimPolicy: Delete [6]
    ```
    1. Name of the StorageClass, this will be referenced in the User ObjectBucketClaim.
    1. Provisioner name
    1. AWS Region that the StorageClass will serve
    1. Name of the bucket owner Secret created above
    1. Namespace where the Secret will exist
    1. reclaimPolicy (Delete or Retain) indicates if the bucket can be deleted when the OBC is deleted.

    **NOTE:** the absence of the `bucketName` Parameter key in the storage class indicates this is a new bucket and its name is based on the bucket name fields in the OBC.

    ```
     # kubectl create -f storageclass-greenfield.yaml
    storageclass.storage.k8s.io/s3-buckets created
    ```

    #### Brownfield Example:

    For brownfield, the StorageClass defines the name of the provisioner and the name of the existing bucket. It also includes other properties needed by the target
    provisioner, including: the Owner Secret and Namespace, and the AWS Region

    1. Create the Kubernetes StorageClass for the Provisioner.
    ```yaml
    kind: StorageClass
    apiVersion: storage.k8s.io/v1
    metadata:
      name: s3-existing-buckets [1]
    provisioner: aws-s3.io/bucket [2]
    parameters:
      bucketName: my-existing-bucket [3]
      region: us-west-1 [4]
      secretName: s3-bucket-owner [5]
      secretNamespace: s3-provisioner [6]
    ```
    1. Name of the StorageClass, this will be referenced in the User ObjectBucketClaim.
    1. Provisioner name
    1. Name of the existing bucket
    1. AWS Region that the StorageClass will serve
    1. Name of the bucket owner Secret created above
    1. Namespace for that bucket owner secret

    **NOTE:** the storage class's `reclaimPolicy` is ignored for existing buckets.

    ```
     # kubectl create -f storageclass-brownfield.yaml
    storageclass.storage.k8s.io/s3-buckets created
    ```

    ### User Creates ObjectBucketClaim
    An ObjectBucketClaim follows the same concept as a PVC, in that
    it is a request for Object Storage, the user doesn't need to
    concern him/herself with the underlying storage, just that
    they need access to it. The user will work with the cluster/storage
    administrator to get the proper StorageClass needed and will
    then request access via the OBC.

    #### Greenfield Request Example:

    1. Create the ObjectBucketClaim.
    ```yaml
    apiVersion: objectbucket.io/v1alpha1
    kind: ObjectBucketClaim
    metadata:
      name: myobc [1]
      namespace: s3-provisioner [2]
    spec:
      generateBucketName: mybucket [3]
      bucketName: my-awesome-bucket [4]
      storageClassName: s3-buckets [5]
    ```
    1. Name of the OBC
    1. Namespace of the OBC
    1. Name prepended to a random string used to generate a bucket name. It is ignored if bucketName is defined
    1. Name of new bucket which must be unique across all AWS regions, otherwise an error occurs when creating the bucket. If present, this name overrides `generateName`
    1. StorageClass name

    **NOTE:** if both `generateBucketName` and `bucketName` are omitted, and the storage class does _not_ define a bucket name, then a new, random bucket name is generated with no prefix.
    ```
     # kubectl create -f obc-brownfield.yaml
    objectbucketclaim.objectbucket.io/myobc created
    ```
    #### Brownfield Request Example:

    1. Create the ObjectBucketClaim.
    ```yaml
    apiVersion: objectbucket.io/v1alpha1
    kind: ObjectBucketClaim
    metadata:
      name: myobc [1]
      namespace: s3-provisioner [2]
    spec:
      storageClassName: s3-existing-buckets [3]
    ```
    1. Name of the OBC
    1. Namespace of the OBC
    1. StorageClass name

    **NOTE:** in the OBC here there is no reference to the bucket's name. This is defined in the storage class and is not a concern of the user creating the claim to this bucket.  An OBC does have fields for defining a bucket name for greenfield use only.
    ```
     # kubectl create -f obc-brownfield.yaml
    objectbucketclaim.objectbucket.io/myobc created
    ```

    ### Results and Recap
    Let's pause for a moment and digest what just happened.
    After creating the OBC, and assuming the S3 provisioner is running, we now have
    the following Kubernetes resources:
    .  a global ObjectBucket (OB) which contains: bucket endpoint info (including region and bucket name), a reference to the OBC, and a reference to the storage class. Unique to S3, the OB also contains the bucket Amazon Resource Name (ARN).Note: there is always a 1:1 relationship between an OBC and an OB.
    .  a ConfigMap in the same namespace as the OBC, which contains the same endpoint data found in the OB.
    .  a Secret in the same namespace as the OBC, which contains the AWS key-pairs needed to access the bucket.

    And of course, we have a *new* AWS S3 Bucket which you should be able to see via the AWS Console.


    *ObjectBucket*
    ```yaml
     # kubectl get ob obc-s3-provisioner-my-awesome-bucket -o yaml
    apiVersion: objectbucket.io/v1alpha1
    kind: ObjectBucket
    metadata:
      creationTimestamp: "2019-04-03T15:42:22Z"
      generation: 1
      name: obc-s3-provisioner-my-awesome-bucket
      resourceVersion: "15057"
      selfLink: /apis/objectbucket.io/v1alpha1/objectbuckets/obc-s3-provisioner-my-awesome-bucket
      uid: 0bfe8e84-576d-4c4e-984b-f73c4460f736
    spec:
      Connection:
        additionalState:
          ARN: arn:aws:iam::<accountid>:policy/my-awesome-bucket-vSgD5 [1]
          UserName: my-awesome-bucket-vSgD5 [2]
        endpoint:
          additionalConfig: null
          bucketHost: s3-us-west-1.amazonaws.com
          bucketName: my-awesome-bucket [3]
          bucketPort: 443
          region: us-west-1
          ssl: true
          subRegion: ""
      claimRef: null [4]
      reclaimPolicy: null
      storageClassName: s3-buckets [5]
    ```
    1. The AWS Policy created for this user and bucket.
    1. The new user generated by the Provisioner to access this existing bucket.
    1. The bucket name.
    1. The reference to the OBC (not filled in yet).
    1. The reference to the StorageClass used.


    *ConfigMap*
    ```yaml
     # kubectl get cm myobc -n s3-provisioner -o yaml
    apiVersion: v1
    data:
      BUCKET_HOST: s3-us-west-1.amazonaws.com [1]
      BUCKET_NAME: my-awesome-bucket [2]
      BUCKET_PORT: "443"
      BUCKET_REGION: us-west-1
      BUCKET_SSL: "true"
      BUCKET_SUBREGION: ""
    kind: ConfigMap
    metadata:
      creationTimestamp: "2019-04-01T19:11:38Z"
      finalizers:
      - objectbucket.io/finalizer
      name: my-awesome-bucket
      namespace: s3-provisioner
      resourceVersion: "892"
      selfLink: /api/v1/namespaces/s3-provisioner/configmaps/my-awesome-bucket
      uid: 2edcc58a-aff8-4a29-814a-ffbb6439a9cd
    ```
    1. The AWS S3 host.
    1. The name of the new bucket we are gaining access to.


    *Secret*
    ```yaml
     # kubectl get secret my-awesome-bucket -n s3-provisioner -o yaml
    apiVersion: v1
    data:
      AWS_ACCESS_KEY_ID: *the_new_access_id* [1]
      AWS_SECRET_ACCESS_KEY: *the_new_access_key_value* [2]
    kind: Secret
    metadata:
      creationTimestamp: "2019-04-03T15:42:22Z"
      finalizers:
      - objectbucket.io/finalizer
      name: my-awesome-bucket
      namespace: s3-provisioner
      resourceVersion: "15058"
      selfLink: /api/v1/namespaces/s3-provisioner/secrets/screeley-provb-5
      uid: 225c71a5-9d75-4ccc-b41f-bfe91b272a13
    type: Opaque
    ```
    1. The new generated AWS Access Key ID.
    1. The new generated AWS Secret Access Key.

    What happened in AWS? The first thing we do on any OBC request is
    create a new IAM user and generate Access ID and Secret Keys.
    This allows us to also better control ACLs. We also create a policy
    in IAM which we then attach to the user and bucket. We also created a new bucket, called *my-awesome-bucket*. 

    When the OBC is deleted all of its Kubernetes and AWS resources will also be deleted, which includes:
    the generated OB, Secret, ConfigMap, IAM user, and policy.
    If the _retainPolicy_ on the StorageClass for this bucket is *"Delete"*, then, in addition to the above cleanup, the physical bucket is also deleted.  

    **NOTE:** The actual bucket is only deleted if the Storage Class's _reclaimPolicy_ is "Delete".

    ### User Creates Pod
    Now that we have our bucket and connection/access information, a pod
    can be used to access the bucket. This can be done in several different
    ways, but the key here is that the provisioner has provided the proper
    endpoints and keys to access the bucket. The user then simply references
    the keys.

    1. Create a Sample Pod to Access the Bucket.
    ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: photo1
      labels:
        name: photo1
    spec:
      containers:
      - name: photo1
        image: docker.io/screeley44/photo-gallery:latest
        imagePullPolicy: Always
        envFrom:
        - configMapRef:
            name: my-awesome-bucket <1>
        - secretRef:
            name: my-awesome-bucket <2>
        ports:
        - containerPort: 3000
          protocol: TCP

    ```
    1. Name of the generated configmap from the provisioning process
    1. Name of the generated secret from the provisioning process

    *[Note]* Generated ConfigMap and Secret are same name as the OBC!

    Lastly, expose the pod as a service so you can access the url from a browser. In this example,
    I exposed as a LoadBalancer

    ``` 
      # kubectl expose pod photo1 --type=LoadBalancer --name=photo1 -n your-namespace
    ```

    To access via a url use the EXTERNAL-IP

    ```
      # kubectl get svc photo1
      NAME                         TYPE           CLUSTER-IP       EXTERNAL-IP                                                               PORT(S)          AGE
      photo1                       LoadBalancer   100.66.124.105   a00c53ccb3c5411e9b6550a7c0e50a2a-2010797808.us-east-1.elb.amazonaws.com   3000:32344/TCP   6d
    ```

    **NOTE:** This is just one example of a Pod that can utilize the bucket information,
    there are several ways that these pod applications can be developed and therefore
    the method of getting the actual values needed from the Secrets and ConfigMaps
    will vary greatly, but the idea remains the same, that the pod consumes the generated
    ConfigMap and Secret created by the provisioner.    
  keywords: ['awss3provisioner', 'aws', 'S3', 'provisioner', 'buckets']

  maintainers:
  - name: Red Hat
    email: openshift-operators@redhat.com

  provider:
    name: Red Hat

  links:
  - name: AWS S3 Provisioner
    url: https://github.com/yard-turkey/aws-s3-provisioner
  - name: Provisioner Examples
    url: https://github.com/yard-turkey/aws-s3-provisioner/tree/master/examples    
  - name: Operator Documentation
    url: https://github.com/yard-turkey/awss3operator

  labels:
    alm-status-descriptors: awss3operator.1.0.1
    alm-owner-awss3: awss3operator

  selector:
    matchLabels:
      alm-owner-awss3: awss3operator

  icon:
  - base64data: PHN2ZyB3aWR0aD0iMjQ5MCIgaGVpZ2h0PSIyNTAwIiB2aWV3Qm94PSIwIDAgMjU2IDI1NyIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiBwcmVzZXJ2ZUFzcGVjdFJhdGlvPSJ4TWlkWU1pZCI+PHBhdGggZD0iTTEyOC4wMDEuNjY3QzU3LjMxMS42NjcgMCA1Ny45NzEgMCAxMjguNjY0YzAgNzAuNjkgNTcuMzExIDEyNy45OTggMTI4LjAwMSAxMjcuOTk4UzI1NiAxOTkuMzU0IDI1NiAxMjguNjY0QzI1NiA1Ny45NyAxOTguNjg5LjY2NyAxMjguMDAxLjY2N3ptMCAyMzkuNTZjLTIwLjExMiAwLTM2LjQxOS0xMy40MzUtMzYuNDE5LTMwLjAwNGg3Mi44MzhjMCAxNi41NjYtMTYuMzA2IDMwLjAwNC0zNi40MTkgMzAuMDA0em02MC4xNTMtMzkuOTRINjcuODQyVjE3OC40N2gxMjAuMzE0djIxLjgxNmgtLjAwMnptLS40MzItMzMuMDQ1SDY4LjE4NWMtLjM5OC0uNDU4LS44MDQtLjkxLTEuMTg4LTEuMzc1LTEyLjMxNS0xNC45NTQtMTUuMjE2LTIyLjc2LTE4LjAzMi0zMC43MTYtLjA0OC0uMjYyIDE0LjkzMyAzLjA2IDI1LjU1NiA1LjQ1IDAgMCA1LjQ2NiAxLjI2NSAxMy40NTggMi43MjItNy42NzMtOC45OTQtMTIuMjMtMjAuNDI4LTEyLjIzLTMyLjExNiAwLTI1LjY1OCAxOS42OC00OC4wNzkgMTIuNTgtNjYuMjAxIDYuOTEuNTYyIDE0LjMgMTQuNTgzIDE0LjggMzYuNTA1IDcuMzQ2LTEwLjE1MiAxMC40Mi0yOC42OSAxMC40Mi00MC4wNTYgMC0xMS43NjkgNy43NTUtMjUuNDQgMTUuNTEyLTI1LjkwNy02LjkxNSAxMS4zOTYgMS43OSAyMS4xNjUgOS41MyA0NS40IDIuOTAyIDkuMTAzIDIuNTMyIDI0LjQyMyA0Ljc3MiAzNC4xMzguNzQ0LTIwLjE3OCA0LjIxMy00OS42MiAxNy4wMTQtNTkuNzg0LTUuNjQ3IDEyLjguODM2IDI4LjgxOCA1LjI3IDM2LjUxOCA3LjE1NCAxMi40MjQgMTEuNDkgMjEuODM2IDExLjQ5IDM5LjYzOCAwIDExLjkzNi00LjQwNyAyMy4xNzMtMTEuODQgMzEuOTU4IDguNDUyLTEuNTg2IDE0LjI4OS0zLjAxNiAxNC4yODktMy4wMTZsMjcuNDUtNS4zNTVjLjAwMi0uMDAyLTMuOTg3IDE2LjQwMS0xOS4zMTQgMzIuMTk3eiIgZmlsbD0iI0RBNEUzMSIvPjwvc3ZnPg==
    mediatype: image/svg+xml

  installModes:
  - type: OwnNamespace
    supported: true
  - type: SingleNamespace
    supported: true
  - type: MultiNamespace
    supported: true
  - type: AllNamespaces
    supported: false

  install:
    strategy: deployment
    spec:
      clusterPermissions:
      - serviceAccountName: aws-s3-provisioner-1-0-1
        rules:
        - apiGroups:
          - objectbucket.io
          resources:
          - objectbucketclaims
          - objectbuckets
          verbs:
          - "*"                
      permissions:
      - serviceAccountName: aws-s3-provisioner-1-0-1
        rules:
        - apiGroups:
          - storage.k8s.io
          resources:
          - storageclasses
          verbs:
          - "*"
        - apiGroups:
          - apiextensions.k8s.io
          resources:
          - customresourcedefinitions
          verbs:
          - "*"
        - apiGroups:
          - ""
          resources:
          - pods
          - services
          - endpoints
          - persistentvolumeclaims
          - persistentvolumes
          - events
          - secrets
          - configmaps
          verbs:
          - "*"
        - apiGroups:
          - apps
          resources:
          - deployments
          verbs:
          - "*"
      deployments:
      - name: aws-s3-provisioner
        spec:
          replicas: 1
          selector:
            matchLabels:
              k8s-app: aws-s3-provisioner
          template:
            metadata:
              labels:
                k8s-app: aws-s3-provisioner
            spec:
              serviceAccount: aws-s3-provisioner-1-0-1
              containers:
              - name: aws-s3-provisioner
                image: quay.io/screeley44/aws-s3-provisioner:v1.0.0
  maturity: alpha
  version: 1.0.1
  customresourcedefinitions:
    owned:
    - name: objectbuckets.objectbucket.io
      version: v1alpha1
      kind: ObjectBucket
      displayName: Object Bucket
      description: instance of an AWS S3 Bucket
    - name: objectbucketclaims.objectbucket.io
      version: v1alpha1
      kind: ObjectBucketClaim
      displayName: Object Bucket Claim
      description: Request for an AWS S3 Bucket
